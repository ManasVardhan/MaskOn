{"cells":[{"cell_type":"code","metadata":{"id":"2W_9iVhRbRz6","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import shutil\n","import time\n","import copy\n","from PIL import Image\n","import glob\n","import cv2"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmsqIDGebYwQ","colab_type":"code","colab":{}},"source":["filepath = 'mask1_model_resnet101.pth'\n","model = torch.load(filepath,map_location='cpu')\n","\n","\n","class_names = ['with_mask',\n"," 'without_mask'\n","]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5tf4VeUb3hb","colab_type":"code","colab":{}},"source":["def process_image(image):\n","    \n","    pil_image = image\n","   \n","    image_transforms = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","    \n","    img = image_transforms(pil_image)\n","    return img"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2xAauHmcO2j","colab_type":"code","colab":{}},"source":["\n","def classify_face(image):\n","    device = torch.device(\"cpu\")\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    im = Image.fromarray(image)\n","    image = process_image(im)\n","    print('image_processed')\n","    img = image.unsqueeze_(0)\n","    img = image.float()\n","\n","    model.eval()\n","    model.cpu()\n","    output = model(image)\n","    print(output,'##############output###########')\n","    _, predicted = torch.max(output, 1)\n","    print(predicted.data[0],\"predicted\")\n","\n","\n","    classification1 = predicted.data[0]\n","    index = int(classification1)\n","    print(class_names[index])\n","    return class_names[index]\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check if your camera is working\n","\n","detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","faces = detector.detectMultiScale(img,1.05)\n","camera = cv2.VideoCapture(0)\n","b,img = camera.read()\n","img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","camera.release()\n","plt.imshow(img)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"opencv_frame_0.png written!\nimage_processed\ntensor([[-2.7373,  2.5699]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nthe label is without_mask\nopencv_frame_1.png written!\nimage_processed\ntensor([[-2.7627,  2.6004]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nthe label is without_mask\nopencv_frame_2.png written!\nimage_processed\ntensor([[-1.2277,  1.1807]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nthe label is without_mask\nopencv_frame_3.png written!\nimage_processed\ntensor([[ 0.3517, -0.2959]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nthe label is with_mask\nEscape hit, closing...\n"}],"source":["# Detect Output when space is pressed , exit when esc is pressed\n","\n","cam = cv2.VideoCapture(0)\n","\n","cv2.namedWindow(\"test\")\n","\n","img_counter = 0\n","\n","while True:\n","    ret, frame = cam.read()\n","    if not ret:\n","        print(\"failed to grab frame\")\n","        break\n","    cv2.imshow(\"test\", frame)\n","\n","    k = cv2.waitKey(1)\n","    if k%256 == 27:\n","        # ESC pressed\n","        print(\"Escape hit, closing...\")\n","        break\n","    elif k%256 == 32:\n","        # SPACE pressed\n","        img_name = \"opencv_frame_{}.png\".format(img_counter)\n","        cv2.imwrite(img_name, frame)\n","        print(\"{} written!\".format(img_name))\n","        img_counter += 1\n","        image = cv2.imread(img_name)\n","        label = classify_face(image)\n","        print(\"the label is\", label)\n","\n","\n","cam.release()\n","\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":"image_processed\ntensor([[-1.0348,  1.0388]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.2931,  1.2343]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.6082,  0.7031]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.2967,  0.2976]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.5361,  1.5346]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.2304,  2.2041]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.0974,  2.0350]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.9970,  1.9016]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.2773,  2.2029]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.2414,  2.1656]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.0021,  2.0370]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.5704,  1.5902]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[0.0554, 0.0640]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[ 0.5848, -0.4218]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[-1.9806,  2.0072]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.2552,  1.2767]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0165,  0.0646]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0292,  0.0631]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.1457,  0.1430]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.9135,  1.8687]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.8721,  1.8068]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.7891,  1.7537]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.2134,  2.1683]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.8027,  1.7884]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.1347,  2.1184]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.1494,  0.2329]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.1726,  0.2609]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0619,  0.1543]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0483,  0.1325]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[0.0064, 0.0893]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0187,  0.1154]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.1778,  1.1977]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-1.5613,  1.6361]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-2.0762,  2.0748]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0998,  0.2494]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.3017,  0.3940]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0678,  0.1547]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0707,  0.1840]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[ 0.0071, -0.0700]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0059, -0.0304]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0059, -0.0304]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0045, -0.0108]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0106, -0.0156]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0229, -0.0476]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0306, -0.0558]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0137, -0.0274]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[-0.0352,  0.0062]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.1373,  0.1401]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.1099,  0.1227]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.7144,  0.7103]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[0.0249, 0.0716]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[0.0026, 0.0550]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0078,  0.0519]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[-0.0033,  0.0102]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(1) predicted\nwithout_mask\nimage_processed\ntensor([[ 0.0195, -0.0269]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0190, -0.0277]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 0.0944, -0.1040]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 1.8147, -1.6579]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2011, -2.0032]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 1.6039, -1.4328]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.6484, -2.2715]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.5009, -2.1644]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.6958, -2.3482]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.5884, -2.2876]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2264, -1.9676]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.4271, -2.1500]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 1.5884, -1.4230]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.3565, -2.0497]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2577, -1.9601]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2764, -1.9806]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 1.2141, -1.0928]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2265, -1.9462]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.3861, -2.1227]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.2548, -2.0011]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.1713, -1.9531]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\nimage_processed\ntensor([[ 2.4075, -2.1316]], grad_fn=<AddmmBackward>) ##############output###########\ntensor(0) predicted\nwith_mask\n"}],"source":["# Predict in Real Time\n","\n","camera = cv2.VideoCapture(0)\n","font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n","\n","while True:\n","    b,img = camera.read()\n","    if b == False:\n","        print(\"Some error\")\n","        continue\n","    \n","    \n","    detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n","    faces = detector.detectMultiScale(img,1.05)\n","    for f in faces:\n","        x,y,w,h = f\n","        green = (0,255,0)\n","        red = (0,0,255)\n","        \n","        label=classify_face(img)\n","        if label == 'without_mask':\n","            cv2.rectangle(img,(x,y),(x+w,y+h),red,2)\n","        elif label == 'with_mask':\n","            cv2.rectangle(img,(x,y),(x+w,y+h),green,2)\n","        cv2.putText(img,str(label),(x,y), font, 1,(255,255,255),1,cv2.LINE_AA)\n","    \n","        cv2.imshow(\"IMAGE\",img)\n","\n","    k = cv2.waitKey(1) & 0xFF\n","    if k == ord('q'): \n","        break\n","    \n","    \n","cv2.destroyAllWindows() \n","camera.release()"]}],"metadata":{"colab":{"name":"detectLabel.ipynb","provenance":[],"mount_file_id":"1mQHxIex2v_lNM8gMTob8cLLiPMH-ZT-F","authorship_tag":"ABX9TyMTBpfB/VtxKfCxV2g9RJr7"},"kernelspec":{"name":"tensor","display_name":"Tensor"}},"nbformat":4,"nbformat_minor":0}